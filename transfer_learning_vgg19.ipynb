{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_vgg19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIeWAHOj0XU"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-v-yUucHRv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "c8b69937-6940-462e-dcc6-093d97600c9d"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "base_model=VGG16(weights='imagenet',include_top=False,input_shape=(32,32,3))\n",
        "for layer in base_model.layers:\n",
        "\tlayer.trainable = False\n",
        "flat1 = tf.keras.layers.Flatten()(base_model.output)\n",
        "output = tf.keras.layers.Dense(55756, activation='softmax')(flat1)\n",
        "model1 = Model(inputs=base_model.inputs, outputs=output)\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 55756)             28602828  \n",
            "=================================================================\n",
            "Total params: 43,317,516\n",
            "Trainable params: 28,602,828\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma2mcvgCVJ6Z"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "input_tensor = Input(shape=(32,32,1) )\n",
        "x = tf.keras.layers.Conv2D(3,(3,3),padding='same')(input_tensor) \n",
        "out = model1 (x) \n",
        "\n",
        "model = Model(inputs=input_tensor,outputs=out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSznTFncW18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3571407a-f2b9-4156-d88d-152532693bbe"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 3)         30        \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 55756)             43317516  \n",
            "=================================================================\n",
            "Total params: 43,317,546\n",
            "Trainable params: 28,602,858\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcEy6EfPVoj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a402d5da-bcf8-4ef3-b83c-b8136da35758"
      },
      "source": [
        "import joblib\n",
        "train_images = joblib.load('/content/drive/My Drive/OULP/test_images_oulp_a2.pkl')\n",
        "train_labels = joblib.load('/content/drive/My Drive/OULP/test_labels_oulp_a2.pkl')\n",
        "validate_images = joblib.load('/content/drive/My Drive/OULP/validate_images_oulp_a3.pkl')\n",
        "validate_labels = joblib.load('/content/drive/My Drive/OULP/validate_labels_oulp_a3.pkl')\n",
        "print(\"=========================================================\")\n",
        "print(\"X_train_orig.shape\", train_images.shape)\n",
        "print(\"Y_train_orig.shape\", train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "X_train_orig.shape (55755, 32, 32)\n",
            "Y_train_orig.shape (55755,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwHJRG0IQLHt"
      },
      "source": [
        "train_images=train_images.reshape(55755,32,32,1)\n",
        "validate_images=validate_images.reshape(55755,32,32,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLXpa1NzfQ6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f00d1da7-dbf0-4a06-8b42-d6be36760285"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 13 07:06:58 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    69W / 149W |    641MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgpXVOEYfSkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2023acd9-f305-426e-fd75-a65dd42b72ba"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history1=model.fit(train_images,train_labels,validation_data=(validate_images,validate_labels),epochs=500,batch_size=128,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "436/436 - 73s - loss: 12.4517 - accuracy: 0.0000e+00 - val_loss: 11.2196 - val_accuracy: 0.0012\n",
            "Epoch 2/500\n",
            "436/436 - 72s - loss: 11.2166 - accuracy: 8.9678e-05 - val_loss: 10.1239 - val_accuracy: 0.0052\n",
            "Epoch 3/500\n",
            "436/436 - 72s - loss: 9.5349 - accuracy: 0.0042 - val_loss: 9.0251 - val_accuracy: 0.0255\n",
            "Epoch 4/500\n",
            "436/436 - 72s - loss: 8.2593 - accuracy: 0.0333 - val_loss: 8.3426 - val_accuracy: 0.0531\n",
            "Epoch 5/500\n",
            "436/436 - 72s - loss: 7.2120 - accuracy: 0.1092 - val_loss: 7.7894 - val_accuracy: 0.0849\n",
            "Epoch 6/500\n",
            "436/436 - 72s - loss: 6.2685 - accuracy: 0.2245 - val_loss: 7.3277 - val_accuracy: 0.1169\n",
            "Epoch 7/500\n",
            "436/436 - 72s - loss: 5.4081 - accuracy: 0.3636 - val_loss: 6.9527 - val_accuracy: 0.1440\n",
            "Epoch 8/500\n",
            "436/436 - 72s - loss: 4.6292 - accuracy: 0.5075 - val_loss: 6.6354 - val_accuracy: 0.1754\n",
            "Epoch 9/500\n",
            "436/436 - 72s - loss: 3.9331 - accuracy: 0.6358 - val_loss: 6.3821 - val_accuracy: 0.1974\n",
            "Epoch 10/500\n",
            "436/436 - 72s - loss: 3.3191 - accuracy: 0.7384 - val_loss: 6.1789 - val_accuracy: 0.2193\n",
            "Epoch 11/500\n",
            "436/436 - 72s - loss: 2.7839 - accuracy: 0.8195 - val_loss: 6.0095 - val_accuracy: 0.2362\n",
            "Epoch 12/500\n",
            "436/436 - 72s - loss: 2.3261 - accuracy: 0.8791 - val_loss: 5.8739 - val_accuracy: 0.2508\n",
            "Epoch 13/500\n",
            "436/436 - 72s - loss: 1.9389 - accuracy: 0.9218 - val_loss: 5.7758 - val_accuracy: 0.2641\n",
            "Epoch 14/500\n",
            "436/436 - 72s - loss: 1.6134 - accuracy: 0.9479 - val_loss: 5.6764 - val_accuracy: 0.2756\n",
            "Epoch 15/500\n",
            "436/436 - 72s - loss: 1.3433 - accuracy: 0.9675 - val_loss: 5.6182 - val_accuracy: 0.2834\n",
            "Epoch 16/500\n",
            "436/436 - 72s - loss: 1.1187 - accuracy: 0.9798 - val_loss: 5.5613 - val_accuracy: 0.2899\n",
            "Epoch 17/500\n",
            "436/436 - 72s - loss: 0.9329 - accuracy: 0.9871 - val_loss: 5.5312 - val_accuracy: 0.2945\n",
            "Epoch 18/500\n",
            "436/436 - 72s - loss: 0.7808 - accuracy: 0.9920 - val_loss: 5.4926 - val_accuracy: 0.3009\n",
            "Epoch 19/500\n",
            "436/436 - 72s - loss: 0.6544 - accuracy: 0.9945 - val_loss: 5.4718 - val_accuracy: 0.3052\n",
            "Epoch 20/500\n",
            "436/436 - 72s - loss: 0.5508 - accuracy: 0.9969 - val_loss: 5.4470 - val_accuracy: 0.3086\n",
            "Epoch 21/500\n",
            "436/436 - 72s - loss: 0.4659 - accuracy: 0.9982 - val_loss: 5.4332 - val_accuracy: 0.3117\n",
            "Epoch 22/500\n",
            "436/436 - 72s - loss: 0.3954 - accuracy: 0.9989 - val_loss: 5.4258 - val_accuracy: 0.3137\n",
            "Epoch 23/500\n",
            "436/436 - 72s - loss: 0.3372 - accuracy: 0.9994 - val_loss: 5.4220 - val_accuracy: 0.3159\n",
            "Epoch 24/500\n",
            "436/436 - 72s - loss: 0.2891 - accuracy: 0.9994 - val_loss: 5.4096 - val_accuracy: 0.3189\n",
            "Epoch 25/500\n",
            "436/436 - 72s - loss: 0.2492 - accuracy: 0.9997 - val_loss: 5.4044 - val_accuracy: 0.3209\n",
            "Epoch 26/500\n",
            "436/436 - 72s - loss: 0.2154 - accuracy: 0.9998 - val_loss: 5.4022 - val_accuracy: 0.3229\n",
            "Epoch 27/500\n",
            "436/436 - 72s - loss: 0.1873 - accuracy: 0.9999 - val_loss: 5.4078 - val_accuracy: 0.3237\n",
            "Epoch 28/500\n",
            "436/436 - 72s - loss: 0.1635 - accuracy: 0.9999 - val_loss: 5.4130 - val_accuracy: 0.3253\n",
            "Epoch 29/500\n",
            "436/436 - 72s - loss: 0.1434 - accuracy: 0.9999 - val_loss: 5.4172 - val_accuracy: 0.3268\n",
            "Epoch 30/500\n",
            "436/436 - 72s - loss: 0.1262 - accuracy: 0.9999 - val_loss: 5.4092 - val_accuracy: 0.3307\n",
            "Epoch 31/500\n",
            "436/436 - 72s - loss: 0.1114 - accuracy: 0.9999 - val_loss: 5.4082 - val_accuracy: 0.3312\n",
            "Epoch 32/500\n",
            "436/436 - 72s - loss: 0.0988 - accuracy: 0.9999 - val_loss: 5.4194 - val_accuracy: 0.3329\n",
            "Epoch 33/500\n",
            "436/436 - 72s - loss: 0.0879 - accuracy: 0.9999 - val_loss: 5.4206 - val_accuracy: 0.3339\n",
            "Epoch 34/500\n",
            "436/436 - 72s - loss: 0.0786 - accuracy: 0.9999 - val_loss: 5.4252 - val_accuracy: 0.3367\n",
            "Epoch 35/500\n",
            "436/436 - 72s - loss: 0.0703 - accuracy: 0.9999 - val_loss: 5.4203 - val_accuracy: 0.3383\n",
            "Epoch 36/500\n",
            "436/436 - 72s - loss: 0.0630 - accuracy: 0.9999 - val_loss: 5.4272 - val_accuracy: 0.3394\n",
            "Epoch 37/500\n",
            "436/436 - 72s - loss: 0.0567 - accuracy: 0.9999 - val_loss: 5.4322 - val_accuracy: 0.3398\n",
            "Epoch 38/500\n",
            "436/436 - 72s - loss: 0.0512 - accuracy: 0.9999 - val_loss: 5.4339 - val_accuracy: 0.3416\n",
            "Epoch 39/500\n",
            "436/436 - 72s - loss: 0.0463 - accuracy: 0.9999 - val_loss: 5.4471 - val_accuracy: 0.3409\n",
            "Epoch 40/500\n",
            "436/436 - 72s - loss: 0.0420 - accuracy: 0.9999 - val_loss: 5.4445 - val_accuracy: 0.3448\n",
            "Epoch 41/500\n",
            "436/436 - 72s - loss: 0.0382 - accuracy: 0.9999 - val_loss: 5.4423 - val_accuracy: 0.3452\n",
            "Epoch 42/500\n",
            "436/436 - 72s - loss: 0.0348 - accuracy: 0.9999 - val_loss: 5.4587 - val_accuracy: 0.3450\n",
            "Epoch 43/500\n",
            "436/436 - 72s - loss: 0.0317 - accuracy: 0.9999 - val_loss: 5.4613 - val_accuracy: 0.3471\n",
            "Epoch 44/500\n",
            "436/436 - 72s - loss: 0.0291 - accuracy: 0.9999 - val_loss: 5.4618 - val_accuracy: 0.3480\n",
            "Epoch 45/500\n",
            "436/436 - 72s - loss: 0.0266 - accuracy: 0.9999 - val_loss: 5.4672 - val_accuracy: 0.3501\n",
            "Epoch 46/500\n",
            "436/436 - 72s - loss: 0.0243 - accuracy: 0.9999 - val_loss: 5.4690 - val_accuracy: 0.3518\n",
            "Epoch 47/500\n",
            "436/436 - 72s - loss: 0.0223 - accuracy: 0.9999 - val_loss: 5.4729 - val_accuracy: 0.3512\n",
            "Epoch 48/500\n",
            "436/436 - 72s - loss: 0.0208 - accuracy: 0.9999 - val_loss: 5.4849 - val_accuracy: 0.3521\n",
            "Epoch 49/500\n",
            "436/436 - 72s - loss: 0.0190 - accuracy: 0.9999 - val_loss: 5.4793 - val_accuracy: 0.3547\n",
            "Epoch 50/500\n",
            "436/436 - 72s - loss: 0.0176 - accuracy: 0.9999 - val_loss: 5.4788 - val_accuracy: 0.3555\n",
            "Epoch 51/500\n",
            "436/436 - 72s - loss: 0.0163 - accuracy: 0.9999 - val_loss: 5.4823 - val_accuracy: 0.3569\n",
            "Epoch 52/500\n",
            "436/436 - 72s - loss: 0.0151 - accuracy: 0.9999 - val_loss: 5.4984 - val_accuracy: 0.3560\n",
            "Epoch 53/500\n",
            "436/436 - 72s - loss: 0.0140 - accuracy: 0.9999 - val_loss: 5.4955 - val_accuracy: 0.3570\n",
            "Epoch 54/500\n",
            "436/436 - 72s - loss: 0.0130 - accuracy: 0.9999 - val_loss: 5.5034 - val_accuracy: 0.3578\n",
            "Epoch 55/500\n",
            "436/436 - 72s - loss: 0.0122 - accuracy: 0.9999 - val_loss: 5.5003 - val_accuracy: 0.3591\n",
            "Epoch 56/500\n",
            "436/436 - 72s - loss: 0.0113 - accuracy: 0.9999 - val_loss: 5.4950 - val_accuracy: 0.3612\n",
            "Epoch 57/500\n",
            "436/436 - 72s - loss: 0.0105 - accuracy: 0.9999 - val_loss: 5.5033 - val_accuracy: 0.3620\n",
            "Epoch 58/500\n",
            "436/436 - 72s - loss: 0.0098 - accuracy: 0.9999 - val_loss: 5.5002 - val_accuracy: 0.3629\n",
            "Epoch 59/500\n",
            "436/436 - 72s - loss: 0.0092 - accuracy: 0.9999 - val_loss: 5.5162 - val_accuracy: 0.3631\n",
            "Epoch 60/500\n",
            "436/436 - 72s - loss: 0.0086 - accuracy: 0.9999 - val_loss: 5.5049 - val_accuracy: 0.3643\n",
            "Epoch 61/500\n",
            "436/436 - 72s - loss: 0.0081 - accuracy: 0.9999 - val_loss: 5.5278 - val_accuracy: 0.3641\n",
            "Epoch 62/500\n",
            "436/436 - 72s - loss: 0.0076 - accuracy: 0.9999 - val_loss: 5.5189 - val_accuracy: 0.3651\n",
            "Epoch 63/500\n",
            "436/436 - 72s - loss: 0.0071 - accuracy: 0.9999 - val_loss: 5.5154 - val_accuracy: 0.3666\n",
            "Epoch 64/500\n",
            "436/436 - 72s - loss: 0.0067 - accuracy: 0.9999 - val_loss: 5.5225 - val_accuracy: 0.3671\n",
            "Epoch 65/500\n",
            "436/436 - 72s - loss: 0.0063 - accuracy: 0.9999 - val_loss: 5.5169 - val_accuracy: 0.3687\n",
            "Epoch 66/500\n",
            "436/436 - 72s - loss: 0.0060 - accuracy: 0.9999 - val_loss: 5.5254 - val_accuracy: 0.3698\n",
            "Epoch 67/500\n",
            "436/436 - 72s - loss: 0.0056 - accuracy: 0.9999 - val_loss: 5.5149 - val_accuracy: 0.3705\n",
            "Epoch 68/500\n",
            "436/436 - 72s - loss: 0.0053 - accuracy: 0.9999 - val_loss: 5.5250 - val_accuracy: 0.3713\n",
            "Epoch 69/500\n",
            "436/436 - 72s - loss: 0.0050 - accuracy: 0.9999 - val_loss: 5.5292 - val_accuracy: 0.3712\n",
            "Epoch 70/500\n",
            "436/436 - 72s - loss: 0.0047 - accuracy: 0.9999 - val_loss: 5.5288 - val_accuracy: 0.3710\n",
            "Epoch 71/500\n",
            "436/436 - 72s - loss: 0.0045 - accuracy: 0.9999 - val_loss: 5.5487 - val_accuracy: 0.3712\n",
            "Epoch 72/500\n",
            "436/436 - 72s - loss: 0.0043 - accuracy: 0.9999 - val_loss: 5.5315 - val_accuracy: 0.3725\n",
            "Epoch 73/500\n",
            "436/436 - 72s - loss: 0.0041 - accuracy: 0.9999 - val_loss: 5.5617 - val_accuracy: 0.3713\n",
            "Epoch 74/500\n",
            "436/436 - 72s - loss: 0.0038 - accuracy: 0.9999 - val_loss: 5.5428 - val_accuracy: 0.3739\n",
            "Epoch 75/500\n",
            "436/436 - 72s - loss: 0.0036 - accuracy: 0.9999 - val_loss: 5.5422 - val_accuracy: 0.3745\n",
            "Epoch 76/500\n",
            "436/436 - 72s - loss: 0.0035 - accuracy: 0.9999 - val_loss: 5.5496 - val_accuracy: 0.3749\n",
            "Epoch 77/500\n",
            "436/436 - 72s - loss: 0.0033 - accuracy: 0.9999 - val_loss: 5.5379 - val_accuracy: 0.3755\n",
            "Epoch 78/500\n",
            "436/436 - 72s - loss: 0.0032 - accuracy: 0.9999 - val_loss: 5.5408 - val_accuracy: 0.3763\n",
            "Epoch 79/500\n",
            "436/436 - 72s - loss: 0.0030 - accuracy: 0.9999 - val_loss: 5.5561 - val_accuracy: 0.3761\n",
            "Epoch 80/500\n",
            "436/436 - 72s - loss: 0.0029 - accuracy: 0.9999 - val_loss: 5.5394 - val_accuracy: 0.3777\n",
            "Epoch 81/500\n",
            "436/436 - 72s - loss: 0.0028 - accuracy: 0.9999 - val_loss: 5.5414 - val_accuracy: 0.3785\n",
            "Epoch 82/500\n",
            "436/436 - 72s - loss: 0.0026 - accuracy: 0.9999 - val_loss: 5.5413 - val_accuracy: 0.3786\n",
            "Epoch 83/500\n",
            "436/436 - 72s - loss: 0.0025 - accuracy: 0.9999 - val_loss: 5.5459 - val_accuracy: 0.3797\n",
            "Epoch 84/500\n",
            "436/436 - 72s - loss: 0.0024 - accuracy: 0.9999 - val_loss: 5.5402 - val_accuracy: 0.3804\n",
            "Epoch 85/500\n",
            "436/436 - 72s - loss: 0.0023 - accuracy: 0.9999 - val_loss: 5.5426 - val_accuracy: 0.3808\n",
            "Epoch 86/500\n",
            "436/436 - 72s - loss: 0.0022 - accuracy: 0.9999 - val_loss: 5.5517 - val_accuracy: 0.3814\n",
            "Epoch 87/500\n",
            "436/436 - 72s - loss: 0.0021 - accuracy: 0.9999 - val_loss: 5.5545 - val_accuracy: 0.3808\n",
            "Epoch 88/500\n",
            "436/436 - 72s - loss: 0.0020 - accuracy: 0.9999 - val_loss: 5.5610 - val_accuracy: 0.3806\n",
            "Epoch 89/500\n",
            "436/436 - 72s - loss: 0.0020 - accuracy: 0.9999 - val_loss: 5.5473 - val_accuracy: 0.3833\n",
            "Epoch 90/500\n",
            "436/436 - 72s - loss: 0.0019 - accuracy: 0.9999 - val_loss: 5.5531 - val_accuracy: 0.3818\n",
            "Epoch 91/500\n",
            "436/436 - 72s - loss: 0.0018 - accuracy: 0.9999 - val_loss: 5.5490 - val_accuracy: 0.3845\n",
            "Epoch 92/500\n",
            "436/436 - 72s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 5.5632 - val_accuracy: 0.3833\n",
            "Epoch 93/500\n",
            "436/436 - 72s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 5.5507 - val_accuracy: 0.3847\n",
            "Epoch 94/500\n",
            "436/436 - 72s - loss: 0.0016 - accuracy: 0.9999 - val_loss: 5.5534 - val_accuracy: 0.3854\n",
            "Epoch 95/500\n",
            "436/436 - 72s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 5.5642 - val_accuracy: 0.3832\n",
            "Epoch 96/500\n",
            "436/436 - 72s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 5.5507 - val_accuracy: 0.3861\n",
            "Epoch 97/500\n",
            "436/436 - 72s - loss: 0.0015 - accuracy: 0.9999 - val_loss: 5.5608 - val_accuracy: 0.3854\n",
            "Epoch 98/500\n",
            "436/436 - 72s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 5.5759 - val_accuracy: 0.3833\n",
            "Epoch 99/500\n",
            "436/436 - 72s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 5.5577 - val_accuracy: 0.3869\n",
            "Epoch 100/500\n",
            "436/436 - 72s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 5.5623 - val_accuracy: 0.3871\n",
            "Epoch 101/500\n",
            "436/436 - 72s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 5.5492 - val_accuracy: 0.3872\n",
            "Epoch 102/500\n",
            "436/436 - 72s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 5.5636 - val_accuracy: 0.3886\n",
            "Epoch 103/500\n",
            "436/436 - 72s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 5.5643 - val_accuracy: 0.3877\n",
            "Epoch 104/500\n",
            "436/436 - 72s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 5.5604 - val_accuracy: 0.3886\n",
            "Epoch 105/500\n",
            "436/436 - 72s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 5.5603 - val_accuracy: 0.3886\n",
            "Epoch 106/500\n",
            "436/436 - 72s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 5.5649 - val_accuracy: 0.3893\n",
            "Epoch 107/500\n",
            "436/436 - 72s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 5.5674 - val_accuracy: 0.3887\n",
            "Epoch 108/500\n",
            "436/436 - 72s - loss: 0.0010 - accuracy: 0.9999 - val_loss: 5.5688 - val_accuracy: 0.3896\n",
            "Epoch 109/500\n",
            "436/436 - 72s - loss: 0.0010 - accuracy: 0.9999 - val_loss: 5.6065 - val_accuracy: 0.3855\n",
            "Epoch 110/500\n",
            "436/436 - 72s - loss: 9.9138e-04 - accuracy: 0.9999 - val_loss: 5.5873 - val_accuracy: 0.3881\n",
            "Epoch 111/500\n",
            "436/436 - 72s - loss: 9.5977e-04 - accuracy: 0.9999 - val_loss: 5.5618 - val_accuracy: 0.3914\n",
            "Epoch 112/500\n",
            "436/436 - 72s - loss: 9.3147e-04 - accuracy: 0.9999 - val_loss: 5.5760 - val_accuracy: 0.3901\n",
            "Epoch 113/500\n",
            "436/436 - 72s - loss: 9.1148e-04 - accuracy: 0.9999 - val_loss: 5.5603 - val_accuracy: 0.3924\n",
            "Epoch 114/500\n",
            "436/436 - 72s - loss: 8.8976e-04 - accuracy: 0.9999 - val_loss: 5.5634 - val_accuracy: 0.3920\n",
            "Epoch 115/500\n",
            "436/436 - 72s - loss: 8.6100e-04 - accuracy: 0.9999 - val_loss: 5.5636 - val_accuracy: 0.3914\n",
            "Epoch 116/500\n",
            "436/436 - 72s - loss: 8.5647e-04 - accuracy: 0.9999 - val_loss: 5.5709 - val_accuracy: 0.3916\n",
            "Epoch 117/500\n",
            "436/436 - 72s - loss: 8.3462e-04 - accuracy: 0.9999 - val_loss: 5.5638 - val_accuracy: 0.3930\n",
            "Epoch 118/500\n",
            "436/436 - 72s - loss: 7.7942e-04 - accuracy: 0.9999 - val_loss: 5.5599 - val_accuracy: 0.3942\n",
            "Epoch 119/500\n",
            "436/436 - 72s - loss: 7.7886e-04 - accuracy: 0.9999 - val_loss: 5.5777 - val_accuracy: 0.3917\n",
            "Epoch 120/500\n",
            "436/436 - 72s - loss: 7.6371e-04 - accuracy: 0.9999 - val_loss: 5.6095 - val_accuracy: 0.3884\n",
            "Epoch 121/500\n",
            "436/436 - 72s - loss: 7.6546e-04 - accuracy: 0.9999 - val_loss: 5.5742 - val_accuracy: 0.3931\n",
            "Epoch 122/500\n",
            "436/436 - 72s - loss: 7.3995e-04 - accuracy: 0.9999 - val_loss: 5.5700 - val_accuracy: 0.3930\n",
            "Epoch 123/500\n",
            "436/436 - 72s - loss: 7.2656e-04 - accuracy: 0.9999 - val_loss: 5.5663 - val_accuracy: 0.3949\n",
            "Epoch 124/500\n",
            "436/436 - 72s - loss: 7.0350e-04 - accuracy: 0.9999 - val_loss: 5.5749 - val_accuracy: 0.3933\n",
            "Epoch 125/500\n",
            "436/436 - 72s - loss: 6.9770e-04 - accuracy: 0.9999 - val_loss: 5.5648 - val_accuracy: 0.3948\n",
            "Epoch 126/500\n",
            "436/436 - 72s - loss: 6.7946e-04 - accuracy: 0.9999 - val_loss: 5.6029 - val_accuracy: 0.3921\n",
            "Epoch 127/500\n",
            "436/436 - 72s - loss: 6.6883e-04 - accuracy: 0.9999 - val_loss: 5.5679 - val_accuracy: 0.3956\n",
            "Epoch 128/500\n",
            "436/436 - 72s - loss: 6.3969e-04 - accuracy: 0.9999 - val_loss: 5.5744 - val_accuracy: 0.3952\n",
            "Epoch 129/500\n",
            "436/436 - 72s - loss: 6.3522e-04 - accuracy: 0.9999 - val_loss: 5.5728 - val_accuracy: 0.3954\n",
            "Epoch 130/500\n",
            "436/436 - 72s - loss: 6.3758e-04 - accuracy: 0.9999 - val_loss: 5.5788 - val_accuracy: 0.3957\n",
            "Epoch 131/500\n",
            "436/436 - 72s - loss: 6.2156e-04 - accuracy: 0.9999 - val_loss: 5.5748 - val_accuracy: 0.3953\n",
            "Epoch 132/500\n",
            "436/436 - 72s - loss: 6.1991e-04 - accuracy: 0.9999 - val_loss: 5.5764 - val_accuracy: 0.3963\n",
            "Epoch 133/500\n",
            "436/436 - 72s - loss: 5.9238e-04 - accuracy: 0.9999 - val_loss: 5.5844 - val_accuracy: 0.3962\n",
            "Epoch 134/500\n",
            "436/436 - 72s - loss: 5.9174e-04 - accuracy: 0.9999 - val_loss: 5.5801 - val_accuracy: 0.3973\n",
            "Epoch 135/500\n",
            "436/436 - 72s - loss: 5.7741e-04 - accuracy: 0.9999 - val_loss: 5.5750 - val_accuracy: 0.3968\n",
            "Epoch 136/500\n",
            "436/436 - 72s - loss: 5.7109e-04 - accuracy: 0.9999 - val_loss: 5.5741 - val_accuracy: 0.3975\n",
            "Epoch 137/500\n",
            "436/436 - 72s - loss: 5.4357e-04 - accuracy: 0.9999 - val_loss: 5.5671 - val_accuracy: 0.3983\n",
            "Epoch 138/500\n",
            "436/436 - 72s - loss: 5.4965e-04 - accuracy: 0.9999 - val_loss: 5.5681 - val_accuracy: 0.3995\n",
            "Epoch 139/500\n",
            "436/436 - 72s - loss: 5.5213e-04 - accuracy: 0.9999 - val_loss: 5.5688 - val_accuracy: 0.3980\n",
            "Epoch 140/500\n",
            "436/436 - 72s - loss: 5.2435e-04 - accuracy: 0.9999 - val_loss: 5.5852 - val_accuracy: 0.3963\n",
            "Epoch 141/500\n",
            "436/436 - 72s - loss: 5.1861e-04 - accuracy: 0.9999 - val_loss: 5.6780 - val_accuracy: 0.3889\n",
            "Epoch 142/500\n",
            "436/436 - 72s - loss: 5.3010e-04 - accuracy: 0.9999 - val_loss: 5.5778 - val_accuracy: 0.3995\n",
            "Epoch 143/500\n",
            "436/436 - 72s - loss: 5.0973e-04 - accuracy: 0.9999 - val_loss: 5.5709 - val_accuracy: 0.3985\n",
            "Epoch 144/500\n",
            "436/436 - 72s - loss: 5.0562e-04 - accuracy: 0.9999 - val_loss: 5.6927 - val_accuracy: 0.3882\n",
            "Epoch 145/500\n",
            "436/436 - 72s - loss: 4.9065e-04 - accuracy: 0.9999 - val_loss: 5.6172 - val_accuracy: 0.3970\n",
            "Epoch 146/500\n",
            "436/436 - 72s - loss: 4.8273e-04 - accuracy: 0.9999 - val_loss: 5.6830 - val_accuracy: 0.3888\n",
            "Epoch 147/500\n",
            "436/436 - 72s - loss: 4.7989e-04 - accuracy: 0.9999 - val_loss: 5.5772 - val_accuracy: 0.4003\n",
            "Epoch 148/500\n",
            "436/436 - 72s - loss: 4.6432e-04 - accuracy: 0.9999 - val_loss: 5.5775 - val_accuracy: 0.3997\n",
            "Epoch 149/500\n",
            "436/436 - 72s - loss: 4.6568e-04 - accuracy: 0.9999 - val_loss: 5.5812 - val_accuracy: 0.4003\n",
            "Epoch 150/500\n",
            "436/436 - 72s - loss: 4.6276e-04 - accuracy: 0.9999 - val_loss: 5.5855 - val_accuracy: 0.3994\n",
            "Epoch 151/500\n",
            "436/436 - 72s - loss: 4.6697e-04 - accuracy: 0.9999 - val_loss: 5.5780 - val_accuracy: 0.4005\n",
            "Epoch 152/500\n",
            "436/436 - 72s - loss: 4.5187e-04 - accuracy: 0.9999 - val_loss: 5.6065 - val_accuracy: 0.3966\n",
            "Epoch 153/500\n",
            "436/436 - 72s - loss: 4.5901e-04 - accuracy: 0.9999 - val_loss: 5.5834 - val_accuracy: 0.4004\n",
            "Epoch 154/500\n",
            "436/436 - 72s - loss: 4.2844e-04 - accuracy: 0.9999 - val_loss: 5.5781 - val_accuracy: 0.4007\n",
            "Epoch 155/500\n",
            "436/436 - 72s - loss: 4.1451e-04 - accuracy: 0.9999 - val_loss: 5.5842 - val_accuracy: 0.4005\n",
            "Epoch 156/500\n",
            "436/436 - 72s - loss: 4.2538e-04 - accuracy: 0.9999 - val_loss: 5.5857 - val_accuracy: 0.4007\n",
            "Epoch 157/500\n",
            "436/436 - 72s - loss: 4.3047e-04 - accuracy: 0.9999 - val_loss: 5.5788 - val_accuracy: 0.4013\n",
            "Epoch 158/500\n",
            "436/436 - 72s - loss: 4.2176e-04 - accuracy: 0.9999 - val_loss: 5.5826 - val_accuracy: 0.4016\n",
            "Epoch 159/500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dExzxwSzffFZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}